{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16da69ad",
   "metadata": {},
   "source": [
    "# ðŸ“˜ 01_data_ingestion.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004b144",
   "metadata": {},
   "source": [
    "# This notebook loads NYC Yellow Taxi Parquet data and merges it into a single DataFrame for further processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87575475",
   "metadata": {},
   "source": [
    "# 1: Imports & Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d8fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id, floor\n",
    "\n",
    "# Set your project root and import config paths\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.config import RAW_DATA_PATH, EXTERNAL_DATA_PATH, PROCESSED_DATA_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e44a60",
   "metadata": {},
   "source": [
    "# 2: Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001add05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spark session initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "def get_spark_session():\n",
    "    try:\n",
    "        spark = SparkSession.builder \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .appName(\"MonthlyNYCIngestion\") \\\n",
    "            .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "            .config(\"spark.driver.memory\", \"4g\") \\\n",
    "            .getOrCreate()\n",
    "        print(\" Spark session initialized successfully.\")\n",
    "        return spark\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to create Spark session: {e}\")\n",
    "        raise\n",
    "\n",
    "spark = get_spark_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b69b7",
   "metadata": {},
   "source": [
    "# 3:  Load Location Lookup CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40630f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+------------+-----------+------------+\n",
      "|LocationID|Borough|                Zone|service_zone|   latitude|   longitude|\n",
      "+----------+-------+--------------------+------------+-----------+------------+\n",
      "|         1|    EWR|      Newark Airport|         EWR|40.69287997|-74.18544993|\n",
      "|         2| Queens|         Jamaica Bay|   Boro Zone|    40.6057|    -73.8713|\n",
      "|         3|  Bronx|Allerton/Pelham G...|   Boro Zone|40.86521003| -73.8435548|\n",
      "+----------+-------+--------------------+------------+-----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_lookup_csv(spark):\n",
    "    return spark.read.option(\"header\", True).csv(EXTERNAL_DATA_PATH)\n",
    "\n",
    "lookup_df = load_lookup_csv(spark)\n",
    "lookup_df.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eeca4d",
   "metadata": {},
   "source": [
    "# 4: Enrichment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9722623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_location(df, lookup_df):\n",
    "    pickup_lookup = lookup_df.drop(\"service_zone\") \\\n",
    "        .withColumnRenamed(\"LocationID\", \"PULocationID\") \\\n",
    "        .withColumnRenamed(\"Zone\", \"pickup_zone\") \\\n",
    "        .withColumnRenamed(\"latitude\", \"pickup_lat\") \\\n",
    "        .withColumnRenamed(\"longitude\", \"pickup_lon\") \\\n",
    "        .withColumnRenamed(\"Borough\", \"pickup_borough\")\n",
    "\n",
    "    dropoff_lookup = lookup_df.drop(\"Borough\") \\\n",
    "        .withColumnRenamed(\"LocationID\", \"DOLocationID\") \\\n",
    "        .withColumnRenamed(\"Zone\", \"dropoff_zone\") \\\n",
    "        .withColumnRenamed(\"latitude\", \"dropoff_lat\") \\\n",
    "        .withColumnRenamed(\"longitude\", \"dropoff_lon\") \\\n",
    "        .withColumnRenamed(\"service_zone\", \"dropoff_service_zone\")\n",
    "\n",
    "    return df.join(pickup_lookup, on=\"PULocationID\", how=\"left\") \\\n",
    "             .join(dropoff_lookup, on=\"DOLocationID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa246282",
   "metadata": {},
   "source": [
    "# 5: Save CSV in Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_in_chunks(df, output_dir, max_rows=1_000_000, month_tag=\"\"):\n",
    "    df_count = df.count()\n",
    "    num_chunks = (df_count // max_rows) + (1 if df_count % max_rows != 0 else 0)\n",
    "\n",
    "    print(f\"Saving {df_count} rows in ~{num_chunks} CSV chunks for {month_tag}...\")\n",
    "\n",
    "    df_with_index = df.withColumn(\"row_num\", monotonically_increasing_id())\n",
    "    df_with_chunk_id = df_with_index.withColumn(\"chunk_id\", floor(col(\"row_num\") / max_rows))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        chunk = df_with_chunk_id.filter(col(\"chunk_id\") == i).drop(\"row_num\", \"chunk_id\")\n",
    "        chunk_path = os.path.join(output_dir, f\"{month_tag}_trip_data_part_{i+1}.csv\")\n",
    "        chunk.write.mode(\"overwrite\").option(\"header\", True).csv(chunk_path)\n",
    "        print(f\"Saved chunk {i+1} to: {chunk_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779a4ad",
   "metadata": {},
   "source": [
    "# 6: Run Ingestion for All Monthly Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62c887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file 1/12: yellow_tripdata_2024-01.parquet\n",
      " Loaded 2964624 raw rows from yellow_tripdata_2024-01.parquet\n",
      " Sample rows for month_4-01:\n",
      "+--------------------+----------------------------+---------------------+\n",
      "|tpep_pickup_datetime|pickup_zone                 |dropoff_zone         |\n",
      "+--------------------+----------------------------+---------------------+\n",
      "|2024-01-01 00:57:55 |Penn Station/Madison Sq West|East Village         |\n",
      "|2024-01-01 00:03:00 |Lenox Hill East             |Upper East Side North|\n",
      "|2024-01-01 00:17:06 |Upper East Side North       |East Village         |\n",
      "+--------------------+----------------------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-01.parquet\n",
      "ðŸ”„ Saving 2754465 rows in ~3 CSV chunks for month_4-01...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-01_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-01_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-01_trip_data_part_3.csv\n",
      "\n",
      "Processing file 2/12: yellow_tripdata_2024-02.parquet\n",
      " Loaded 3007526 raw rows from yellow_tripdata_2024-02.parquet\n",
      " Sample rows for month_4-02:\n",
      "+--------------------+------------+------------------------+\n",
      "|tpep_pickup_datetime|pickup_zone |dropoff_zone            |\n",
      "+--------------------+------------+------------------------+\n",
      "|2024-02-01 00:04:45 |East Chelsea|Upper East Side North   |\n",
      "|2024-02-01 00:56:31 |Clinton East|Washington Heights North|\n",
      "|2024-02-01 00:07:50 |JFK Airport |World Trade Center      |\n",
      "+--------------------+------------+------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-02.parquet\n",
      "ðŸ”„ Saving 2752623 rows in ~3 CSV chunks for month_4-02...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-02_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-02_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-02_trip_data_part_3.csv\n",
      "\n",
      "Processing file 3/12: yellow_tripdata_2024-03.parquet\n",
      " Loaded 3582628 raw rows from yellow_tripdata_2024-03.parquet\n",
      " Sample rows for month_4-03:\n",
      "+--------------------+---------------------+---------------------+\n",
      "|tpep_pickup_datetime|pickup_zone          |dropoff_zone         |\n",
      "+--------------------+---------------------+---------------------+\n",
      "|2024-03-01 00:18:51 |Lincoln Square East  |Upper West Side South|\n",
      "|2024-03-01 00:26:00 |Upper West Side North|Bloomingdale         |\n",
      "|2024-03-01 00:09:22 |Yorkville West       |East Harlem South    |\n",
      "+--------------------+---------------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-03.parquet\n",
      "ðŸ”„ Saving 3074878 rows in ~4 CSV chunks for month_4-03...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-03_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-03_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-03_trip_data_part_3.csv\n",
      "ðŸ“ Saved chunk 4 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-03_trip_data_part_4.csv\n",
      "\n",
      "Processing file 4/12: yellow_tripdata_2024-04.parquet\n",
      " Loaded 3514289 raw rows from yellow_tripdata_2024-04.parquet\n",
      " Sample rows for month_4-04:\n",
      "+--------------------+----------------------------+---------------------+\n",
      "|tpep_pickup_datetime|pickup_zone                 |dropoff_zone         |\n",
      "+--------------------+----------------------------+---------------------+\n",
      "|2024-04-01 00:02:40 |Midtown Center              |Astoria              |\n",
      "|2024-04-01 00:41:12 |NV                          |NV                   |\n",
      "|2024-04-01 00:48:42 |Penn Station/Madison Sq West|Upper East Side North|\n",
      "+--------------------+----------------------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-04.parquet\n",
      "ðŸ”„ Saving 3025749 rows in ~4 CSV chunks for month_4-04...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-04_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-04_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-04_trip_data_part_3.csv\n",
      "ðŸ“ Saved chunk 4 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-04_trip_data_part_4.csv\n",
      "\n",
      "Processing file 5/12: yellow_tripdata_2024-05.parquet\n",
      " Loaded 3723833 raw rows from yellow_tripdata_2024-05.parquet\n",
      " Sample rows for month_4-05:\n",
      "+--------------------+-----------------+------------------------------+\n",
      "|tpep_pickup_datetime|pickup_zone      |dropoff_zone                  |\n",
      "+--------------------+-----------------+------------------------------+\n",
      "|2024-05-01 00:59:15 |LaGuardia Airport|Long Island City/Hunters Point|\n",
      "|2024-04-30 23:58:26 |LaGuardia Airport|West Village                  |\n",
      "|2024-05-01 00:57:17 |LaGuardia Airport|Murray Hill                   |\n",
      "+--------------------+-----------------+------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-05.parquet\n",
      "ðŸ”„ Saving 3230606 rows in ~4 CSV chunks for month_4-05...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-05_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-05_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-05_trip_data_part_3.csv\n",
      "ðŸ“ Saved chunk 4 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-05_trip_data_part_4.csv\n",
      "\n",
      "Processing file 6/12: yellow_tripdata_2024-06.parquet\n",
      " Loaded 3539193 raw rows from yellow_tripdata_2024-06.parquet\n",
      " Sample rows for month_4-06:\n",
      "+--------------------+-------------------+--------------+\n",
      "|tpep_pickup_datetime|pickup_zone        |dropoff_zone  |\n",
      "+--------------------+-------------------+--------------+\n",
      "|2024-06-01 00:03:46 |LaGuardia Airport  |Red Hook      |\n",
      "|2024-06-01 00:55:22 |LaGuardia Airport  |Astoria       |\n",
      "|2024-06-01 00:23:53 |Morningside Heights|Central Harlem|\n",
      "+--------------------+-------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-06.parquet\n",
      "ðŸ”„ Saving 3040798 rows in ~4 CSV chunks for month_4-06...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-06_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-06_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-06_trip_data_part_3.csv\n",
      "ðŸ“ Saved chunk 4 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-06_trip_data_part_4.csv\n",
      "\n",
      "Processing file 7/12: yellow_tripdata_2024-07.parquet\n",
      " Loaded 3076903 raw rows from yellow_tripdata_2024-07.parquet\n",
      " Sample rows for month_4-07:\n",
      "+--------------------+---------------------+------------------------------+\n",
      "|tpep_pickup_datetime|pickup_zone          |dropoff_zone                  |\n",
      "+--------------------+---------------------+------------------------------+\n",
      "|2024-07-01 00:34:56 |Lenox Hill East      |East Village                  |\n",
      "|2024-06-30 23:48:58 |JFK Airport          |Greenwich Village North       |\n",
      "|2024-07-01 00:23:18 |Upper East Side South|Long Island City/Hunters Point|\n",
      "+--------------------+---------------------+------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-07.parquet\n",
      "ðŸ”„ Saving 2710909 rows in ~3 CSV chunks for month_4-07...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-07_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-07_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-07_trip_data_part_3.csv\n",
      "\n",
      "Processing file 8/12: yellow_tripdata_2024-08.parquet\n",
      " Loaded 2979183 raw rows from yellow_tripdata_2024-08.parquet\n",
      " Sample rows for month_4-08:\n",
      "+--------------------+-----------------+------------------------+\n",
      "|tpep_pickup_datetime|pickup_zone      |dropoff_zone            |\n",
      "+--------------------+-----------------+------------------------+\n",
      "|2024-08-01 00:21:00 |LaGuardia Airport|East Williamsburg       |\n",
      "|2024-08-01 00:20:01 |LaGuardia Airport|Upper West Side South   |\n",
      "|2024-08-01 00:17:52 |LaGuardia Airport|Financial District South|\n",
      "+--------------------+-----------------+------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-08.parquet\n",
      "ðŸ”„ Saving 2628753 rows in ~3 CSV chunks for month_4-08...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-08_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-08_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-08_trip_data_part_3.csv\n",
      "\n",
      "Processing file 9/12: yellow_tripdata_2024-09.parquet\n",
      " Loaded 3633030 raw rows from yellow_tripdata_2024-09.parquet\n",
      " Sample rows for month_4-09:\n",
      "+--------------------+---------------------+---------------+\n",
      "|tpep_pickup_datetime|pickup_zone          |dropoff_zone   |\n",
      "+--------------------+---------------------+---------------+\n",
      "|2024-09-01 00:05:51 |LaGuardia Airport    |Clinton East   |\n",
      "|2024-09-01 00:59:35 |Lenox Hill East      |Lenox Hill West|\n",
      "|2024-09-01 00:25:00 |Upper West Side North|Manhattanville |\n",
      "+--------------------+---------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-09.parquet\n",
      "ðŸ”„ Saving 3053206 rows in ~4 CSV chunks for month_4-09...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-09_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-09_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-09_trip_data_part_3.csv\n",
      "ðŸ“ Saved chunk 4 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-09_trip_data_part_4.csv\n",
      "\n",
      "Processing file 10/12: yellow_tripdata_2024-10.parquet\n",
      " Loaded 3833771 raw rows from yellow_tripdata_2024-10.parquet\n",
      " Sample rows for month_4-10:\n",
      "+--------------------+-------------------+-------------------------+\n",
      "|tpep_pickup_datetime|pickup_zone        |dropoff_zone             |\n",
      "+--------------------+-------------------+-------------------------+\n",
      "|2024-10-01 00:30:44 |Midtown East       |West Chelsea/Hudson Yards|\n",
      "|2024-10-01 00:12:20 |Clinton East       |Upper East Side North    |\n",
      "|2024-10-01 00:04:46 |Lincoln Square East|Bloomingdale             |\n",
      "+--------------------+-------------------+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-10.parquet\n",
      "ðŸ”„ Saving 3336488 rows in ~4 CSV chunks for month_4-10...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-10_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-10_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-10_trip_data_part_3.csv\n",
      "ðŸ“ Saved chunk 4 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-10_trip_data_part_4.csv\n",
      "\n",
      "Processing file 11/12: yellow_tripdata_2024-11.parquet\n",
      " Loaded 3646369 raw rows from yellow_tripdata_2024-11.parquet\n",
      " Sample rows for month_4-11:\n",
      "+--------------------+----------------------------+--------------+\n",
      "|tpep_pickup_datetime|pickup_zone                 |dropoff_zone  |\n",
      "+--------------------+----------------------------+--------------+\n",
      "|2024-11-01 00:46:24 |Upper West Side South       |Yorkville West|\n",
      "|2024-11-01 00:37:36 |Springfield Gardens South   |NA            |\n",
      "|2024-11-01 00:12:55 |Penn Station/Madison Sq West|Gramercy      |\n",
      "+--------------------+----------------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-11.parquet\n",
      "ðŸ”„ Saving 3174829 rows in ~4 CSV chunks for month_4-11...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-11_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-11_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-11_trip_data_part_3.csv\n",
      "ðŸ“ Saved chunk 4 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-11_trip_data_part_4.csv\n",
      "\n",
      "Processing file 12/12: yellow_tripdata_2024-12.parquet\n",
      " Loaded 3668371 raw rows from yellow_tripdata_2024-12.parquet\n",
      " Sample rows for month_4-12:\n",
      "+--------------------+-----------------------------+---------------------+\n",
      "|tpep_pickup_datetime|pickup_zone                  |dropoff_zone         |\n",
      "+--------------------+-----------------------------+---------------------+\n",
      "|2024-12-01 00:12:27 |LaGuardia Airport            |Brooklyn Heights     |\n",
      "|2024-11-30 23:56:04 |Meatpacking/West Village West|Central Harlem North |\n",
      "|2024-12-01 00:50:35 |JFK Airport                  |Upper East Side North|\n",
      "+--------------------+-----------------------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Saved cleaned Parquet to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\month_4-12.parquet\n",
      "ðŸ”„ Saving 3229531 rows in ~4 CSV chunks for month_4-12...\n",
      "ðŸ“ Saved chunk 1 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-12_trip_data_part_1.csv\n",
      "ðŸ“ Saved chunk 2 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-12_trip_data_part_2.csv\n",
      "ðŸ“ Saved chunk 3 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-12_trip_data_part_3.csv\n",
      "ðŸ“ Saved chunk 4 to: c:\\Users\\VaishnaviM\\Desktop\\BIG_DATA\\data\\processed\\csv_chunks\\month_4-12_trip_data_part_4.csv\n"
     ]
    }
   ],
   "source": [
    "input_files = sorted([f for f in os.listdir(RAW_DATA_PATH) if f.endswith(\".parquet\")])\n",
    "if not input_files:\n",
    "    raise FileNotFoundError(\"No Parquet files found in RAW_DATA_PATH.\")\n",
    "\n",
    "for idx, filename in enumerate(input_files, 1):\n",
    "    print(f\"\\nProcessing file {idx}/{len(input_files)}: {filename}\")\n",
    "    file_path = os.path.join(RAW_DATA_PATH, filename)\n",
    "\n",
    "    # Month tag from filename\n",
    "    month_tag = f\"month_{filename[-12:-8]}\" if \"-\" in filename else f\"month_{idx:02d}\"\n",
    "\n",
    "    # Step 1: Load Parquet\n",
    "    df = spark.read.parquet(file_path)\n",
    "    print(f\" Loaded {df.count()} raw rows from {filename}\")\n",
    "\n",
    "    # Step 2: Clean\n",
    "    cleaned_df = df.dropna().filter(\"trip_distance > 0 AND fare_amount > 0\")\n",
    "\n",
    "    # Step 3: Enrich\n",
    "    enriched_df = enrich_with_location(cleaned_df, lookup_df)\n",
    "\n",
    "    # Preview\n",
    "    print(f\" Sample rows for {month_tag}:\")\n",
    "    enriched_df.select(\"tpep_pickup_datetime\", \"pickup_zone\", \"dropoff_zone\").show(3, truncate=False)\n",
    "\n",
    "    # Step 4: Save Parquet\n",
    "    parquet_output_path = os.path.join(PROCESSED_DATA_PATH, f\"{month_tag}.parquet\")\n",
    "    enriched_df.coalesce(1).write.mode(\"overwrite\").parquet(parquet_output_path)\n",
    "    print(f\"Saved cleaned Parquet to: {parquet_output_path}\")\n",
    "\n",
    "    # Step 5: Save CSV Chunks\n",
    "    csv_output_dir = os.path.join(PROCESSED_DATA_PATH, \"csv_chunks\")\n",
    "    save_csv_in_chunks(enriched_df, csv_output_dir, month_tag=month_tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a00b6",
   "metadata": {},
   "source": [
    "# 7: Stop Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bea9d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›‘ Spark session stopped.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"ðŸ›‘ Spark session stopped.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
